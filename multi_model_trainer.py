# ==============================
# MULTI-MODEL TRAINER
# √áoklu Model Mimarisi Eƒüitimi ve Kar≈üƒ±la≈ütƒ±rma
# ==============================

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from pathlib import Path
import json
import config
import utils

logger = utils.setup_logging(__name__)

# ==============================
# MODEL FACTORY
# ==============================

class ModelFactory:
    """Farklƒ± model mimarilerini olu≈ütur"""
    
    @staticmethod
    def create_model(
        model_name: str,
        num_classes: int,
        input_shape: tuple = None
    ) -> tuple:
        """
        Model olu≈ütur
        
        Args:
            model_name: Model adƒ± ('mobilenetv2', 'efficientnetb0', etc.)
            num_classes: Sƒ±nƒ±f sayƒ±sƒ±
            input_shape: Girdi boyutu
        
        Returns:
            (model, base_model) tuple
        """
        if input_shape is None:
            input_shape = config.AVAILABLE_MODELS[model_name]['input_size'] + (3,)
        
        logger.info(f"Model olu≈üturuluyor: {model_name}")
        
        if model_name == 'mobilenetv2':
            base_model = tf.keras.applications.MobileNetV2(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        
        elif model_name == 'efficientnetb0':
            base_model = tf.keras.applications.EfficientNetB0(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        
        elif model_name == 'efficientnetb3':
            base_model = tf.keras.applications.EfficientNetB3(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        
        elif model_name == 'resnet50':
            base_model = tf.keras.applications.ResNet50(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        
        else:
            raise ValueError(f"Desteklenmeyen model: {model_name}")
        
        # Base model'i dondur
        base_model.trainable = False
        
        # Sƒ±nƒ±flandƒ±rma katmanlarƒ±
        x = base_model.output
        x = tf.keras.layers.GlobalAveragePooling2D()(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dense(256, activation='relu')(x)
        x = tf.keras.layers.Dropout(0.5)(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dense(128, activation='relu')(x)
        x = tf.keras.layers.Dropout(0.3)(x)
        output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
        
        model = tf.keras.models.Model(inputs=base_model.input, outputs=output)
        
        return model, base_model

# ==============================
# MULTI-MODEL TRAINER
# ==============================

class MultiModelTrainer:
    """Birden fazla model mimarisini eƒüit ve kar≈üƒ±la≈ütƒ±r"""
    
    def __init__(
        self,
        model_names: list = None,
        data_dir: Path = config.DATA_DIR,
        save_dir: Path = config.MODELS_DIR
    ):
        """
        Args:
            model_names: Eƒüitilecek model isimleri
            data_dir: Veri dizini
            save_dir: Model kayƒ±t dizini
        """
        self.model_names = model_names or ['mobilenetv2', 'efficientnetb0', 'resnet50']
        self.data_dir = Path(data_dir)
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True, parents=True)
        
        self.models = {}
        self.histories = {}
        self.results = {}
        
        logger.info(f"Eƒüitilecek modeller: {self.model_names}")
    
    def prepare_data(self, model_name: str):
        """Veri setini hazƒ±rla"""
        img_size = config.AVAILABLE_MODELS[model_name]['input_size']
        
        # Data generators
        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rescale=1./255,
            validation_split=config.VALIDATION_SPLIT,
            **config.AUGMENTATION_CONFIG
        )
        
        val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rescale=1./255,
            validation_split=config.VALIDATION_SPLIT
        )
        
        train_data = train_datagen.flow_from_directory(
            self.data_dir,
            target_size=img_size,
            batch_size=config.BATCH_SIZE,
            class_mode='categorical',
            subset='training',
            shuffle=True
        )
        
        val_data = val_datagen.flow_from_directory(
            self.data_dir,
            target_size=img_size,
            batch_size=config.BATCH_SIZE,
            class_mode='categorical',
            subset='validation',
            shuffle=False
        )
        
        return train_data, val_data
    
    def train_model(
        self,
        model_name: str,
        epochs: int = config.EPOCHS,
        verbose: int = 1
    ):
        """Tek bir modeli eƒüit"""
        logger.info(f"\n{'='*60}")
        logger.info(f"MODEL Eƒûƒ∞Tƒ∞Mƒ∞: {model_name.upper()}")
        logger.info(f"{'='*60}")
        
        # Veri hazƒ±rla
        train_data, val_data = self.prepare_data(model_name)
        num_classes = train_data.num_classes
        
        # Model olu≈ütur
        model, base_model = ModelFactory.create_model(model_name, num_classes)
        
        # Callbacks
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                **config.CALLBACKS_CONFIG['early_stopping'],
                verbose=1
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                **config.CALLBACKS_CONFIG['reduce_lr'],
                verbose=1
            ),
            tf.keras.callbacks.ModelCheckpoint(
                str(self.save_dir / f"{model_name}_best.keras"),
                **config.CALLBACKS_CONFIG['model_checkpoint'],
                verbose=1
            ),
            tf.keras.callbacks.TensorBoard(
                log_dir=str(config.LOGS_DIR / f"fit/{model_name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}"),
                histogram_freq=1
            )
        ]
        
        # Model derle
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),
            loss='categorical_crossentropy',
            metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]
        )
        
        # Eƒüitim
        logger.info(f"\nüöÄ Eƒüitim ba≈ülƒ±yor (1. A≈üama - Frozen Base)...")
        history1 = model.fit(
            train_data,
            validation_data=val_data,
            epochs=epochs,
            callbacks=callbacks,
            verbose=verbose
        )
        
        # Fine-tuning
        logger.info(f"\nüîß Fine-tuning ba≈ülƒ±yor (2. A≈üama)...")
        base_model.trainable = True
        
        # ƒ∞lk katmanlarƒ± dondur
        for layer in base_model.layers[:int(len(base_model.layers) * 0.7)]:
            layer.trainable = False
        
        # Yeniden derle
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE / 10),
            loss='categorical_crossentropy',
            metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]
        )
        
        # Fine-tuning eƒüitimi
        history2 = model.fit(
            train_data,
            validation_data=val_data,
            epochs=10,
            callbacks=callbacks,
            verbose=verbose
        )
        
        # Ge√ßmi≈üi birle≈ütir
        combined_history = {
            'accuracy': history1.history['accuracy'] + history2.history['accuracy'],
            'val_accuracy': history1.history['val_accuracy'] + history2.history['val_accuracy'],
            'loss': history1.history['loss'] + history2.history['loss'],
            'val_loss': history1.history['val_loss'] + history2.history['val_loss']
        }
        
        # Kaydet
        self.models[model_name] = model
        self.histories[model_name] = combined_history
        
        # Deƒüerlendirme
        logger.info(f"\nüìä Model deƒüerlendiriliyor...")
        val_loss, val_acc, val_top3 = model.evaluate(val_data, verbose=0)
        
        self.results[model_name] = {
            'val_loss': float(val_loss),
            'val_accuracy': float(val_acc),
            'val_top3_accuracy': float(val_top3),
            'total_epochs': len(combined_history['accuracy']),
            'best_val_accuracy': float(max(combined_history['val_accuracy'])),
            'model_params': model.count_params()
        }
        
        logger.info(f"\n‚úÖ {model_name} eƒüitimi tamamlandƒ±!")
        logger.info(f"Validation Accuracy: {val_acc:.4f}")
        logger.info(f"Validation Top-3 Accuracy: {val_top3:.4f}")
        
        return model, combined_history
    
    def train_all(self, epochs: int = config.EPOCHS):
        """T√ºm modelleri eƒüit"""
        logger.info(f"\n{'='*60}")
        logger.info(f"T√úM MODELLER Eƒûƒ∞Tƒ∞Lƒ∞YOR")
        logger.info(f"{'='*60}")
        logger.info(f"Modeller: {', '.join(self.model_names)}")
        logger.info(f"Epoch: {epochs}")
        
        for model_name in self.model_names:
            try:
                self.train_model(model_name, epochs=epochs)
            except Exception as e:
                logger.error(f"‚ùå {model_name} eƒüitimi ba≈üarƒ±sƒ±z: {e}")
                continue
        
        # Sonu√ßlarƒ± kaydet
        self.save_results()
        
        # Kar≈üƒ±la≈ütƒ±rma
        self.compare_models()
    
    def save_results(self):
        """Sonu√ßlarƒ± kaydet"""
        results_file = self.save_dir / "model_comparison_results.json"
        utils.save_json(self.results, results_file)
        logger.info(f"üìÅ Sonu√ßlar kaydedildi: {results_file}")
    
    def compare_models(self):
        """Modelleri kar≈üƒ±la≈ütƒ±r"""
        if not self.results:
            logger.warning("Kar≈üƒ±la≈ütƒ±rƒ±lacak sonu√ß yok!")
            return
        
        logger.info(f"\n{'='*60}")
        logger.info("MODEL KAR≈ûILA≈ûTIRMA")
        logger.info(f"{'='*60}")
        
        # Tablo olu≈ütur
        print(f"\n{'Model':<20} {'Val Acc':<12} {'Top-3 Acc':<12} {'Params':<15}")
        print("-" * 60)
        
        for model_name, results in self.results.items():
            print(f"{model_name:<20} "
                  f"{results['val_accuracy']:<12.4f} "
                  f"{results['val_top3_accuracy']:<12.4f} "
                  f"{results['model_params']:<15,}")
        
        # G√∂rselle≈ütirme
        self.plot_comparison()
    
    def plot_comparison(self):
        """Kar≈üƒ±la≈ütƒ±rma grafikleri"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Validation Accuracy
        ax = axes[0, 0]
        models = list(self.results.keys())
        val_accs = [self.results[m]['val_accuracy'] for m in models]
        
        bars = ax.bar(models, val_accs, color='skyblue', edgecolor='navy')
        ax.set_ylabel('Validation Accuracy', fontsize=12)
        ax.set_title('Model Validation Accuracy Kar≈üƒ±la≈ütƒ±rmasƒ±', fontsize=14, fontweight='bold')
        ax.set_ylim([min(val_accs) - 0.05, 1.0])
        
        # Deƒüerleri g√∂ster
        for bar, val in zip(bars, val_accs):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.4f}', ha='center', va='bottom', fontsize=10)
        
        # 2. Model Parameters
        ax = axes[0, 1]
        params = [self.results[m]['model_params'] / 1e6 for m in models]  # Millions
        
        bars = ax.bar(models, params, color='lightcoral', edgecolor='darkred')
        ax.set_ylabel('Parameters (Millions)', fontsize=12)
        ax.set_title('Model Parametre Sayƒ±sƒ±', fontsize=14, fontweight='bold')
        
        for bar, val in zip(bars, params):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.2f}M', ha='center', va='bottom', fontsize=10)
        
        # 3. Training History
        ax = axes[1, 0]
        for model_name, history in self.histories.items():
            ax.plot(history['val_accuracy'], label=model_name, linewidth=2)
        
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('Validation Accuracy', fontsize=12)
        ax.set_title('Eƒüitim Ge√ßmi≈üi Kar≈üƒ±la≈ütƒ±rmasƒ±', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. Top-3 Accuracy
        ax = axes[1, 1]
        top3_accs = [self.results[m]['val_top3_accuracy'] for m in models]
        
        bars = ax.bar(models, top3_accs, color='lightgreen', edgecolor='darkgreen')
        ax.set_ylabel('Top-3 Accuracy', fontsize=12)
        ax.set_title('Model Top-3 Accuracy Kar≈üƒ±la≈ütƒ±rmasƒ±', fontsize=14, fontweight='bold')
        ax.set_ylim([min(top3_accs) - 0.05, 1.0])
        
        for bar, val in zip(bars, top3_accs):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.4f}', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        save_path = config.RESULTS_DIR / "model_comparison.png"
        plt.savefig(save_path, dpi=300)
        logger.info(f"üìä Kar≈üƒ±la≈ütƒ±rma grafiƒüi kaydedildi: {save_path}")
        
        plt.show()

# ==============================
# MAIN EXECUTION
# ==============================

if __name__ == "__main__":
    print("=" * 60)
    print("√áOK MODELLƒ∞ Eƒûƒ∞Tƒ∞M Sƒ∞STEMƒ∞")
    print("=" * 60)
    
    # Trainer olu≈ütur
    trainer = MultiModelTrainer(
        model_names=['mobilenetv2', 'efficientnetb0', 'resnet50']
    )
    
    # T√ºm modelleri eƒüit
    trainer.train_all(epochs=15)
    
    print("\n‚úÖ T√ºm modeller eƒüitildi ve kar≈üƒ±la≈ütƒ±rƒ±ldƒ±!")
    print(f"üìÅ Modeller: {config.MODELS_DIR}")
    print(f"üìÅ Sonu√ßlar: {config.RESULTS_DIR}")
